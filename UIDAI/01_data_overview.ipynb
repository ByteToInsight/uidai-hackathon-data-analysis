{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01. Data Overview",
        "",
        "Objective: Load all datasets, inspect schemas, and validate data integrity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd",
        "import glob",
        "import os",
        "",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_files = {",
        "    'Enrolment': 'data/enrolment_sample.csv',",
        "    'Biometric': 'data/biometric_sample.csv',",
        "    'Demographic': 'data/demographic_sample.csv',",
        "    'Authentication': 'data/authentication_sample.csv'",
        "}",
        "",
        "dfs = {}",
        "for name, path in data_files.items():",
        "    if os.path.exists(path):",
        "        dfs[name] = pd.read_csv(path)",
        "        print(f\"Loaded {name}: {dfs[name].shape}\")",
        "    else:",
        "        print(f\"Warning: {path} not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Basic Inspection",
        "Display head, info, and describe for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, df in dfs.items():",
        "    print(f\"\\n{'='*20}\\n{name} Dataset\\n{'='*20}\")",
        "    display(df.head())",
        "    print(\"\\n--- Info ---\")",
        "    df.info()",
        "    print(\"\\n--- Description ---\")",
        "    display(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Schema Validation",
        "Check for expected columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "expected_cols = {",
        "    'Enrolment': ['State', 'District', 'Date', 'age_0_5', 'age_5_17', 'age_18_greater'],",
        "    'Biometric': ['State', 'District', 'Date', 'bio_age_5_17', 'bio_age_17_'],",
        "    'Demographic': ['State', 'District', 'Date', 'demo_age_5_17', 'demo_age_17_']",
        "}",
        "",
        "for name, cols in expected_cols.items():",
        "    if name in dfs:",
        "        missing = [c for c in cols if c not in dfs[name].columns]",
        "        if missing:",
        "            print(f\"ERROR: {name} missing columns: {missing}\")",
        "        else:",
        "            print(f\"SUCCESS: {name} contains all expected columns.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}